{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 11:28:21.432975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file_path):\n",
    "    with open(file_path) as f:\n",
    "        return f.read()\n",
    "\n",
    "euro_en = load_db('pt-en/europarl-v7.pt-en.en')\n",
    "euro_pt = load_db('pt-en/europarl-v7.pt-en.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en sample example:  Resumption of the session\n",
      "pt sample example:  Reinício da sessão\n"
     ]
    }
   ],
   "source": [
    "print('en sample example: ', euro_en.split('\\n')[0])\n",
    "print('pt sample example: ', euro_pt.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data en:  Would it be appropriate for you, Madam President, to write a letter to the Sri Lankan President expressing Parliament's regret at his and the other violent deaths in Sri Lanka and urging her to do everything she possibly can to seek a peaceful reconciliation to a very difficult situation?\n",
      "Data pt:  Será que a senhora Presidente poderia enviar uma carta à Presidente do Sri Lanka manifestando o pesar do Parlamento por esta e outras mortes violentas perpetradas no seu país, e instando­a a envidar todos os esforços ao seu alcance para procurar obter uma reconciliação pacífica na situação extremamente difícil que ali se vive?\n"
     ]
    }
   ],
   "source": [
    "def data_cleaning(data):\n",
    "    data = re.sub(r'\\.(?=[0-9]|[a-z]|[A-Z])', '$$', data)\n",
    "    data = re.sub(r'\\$\\$', '', data)\n",
    "    data = re.sub(r' +', ' ', data)\n",
    "    return data.split('\\n')\n",
    "\n",
    "data_en = data_cleaning(data=euro_en)\n",
    "data_pt = data_cleaning(data=euro_pt)\n",
    "\n",
    "print('Data en: ', data_en[10])\n",
    "print('Data pt: ', data_pt[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en data size: 1960408 | pt data size: 1960408\n"
     ]
    }
   ],
   "source": [
    "print('en data size: {} | pt data size: {}'.format(len(data_en), len(data_pt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En vocab size:  8191\n",
      "Pt vocab size:  8116\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_data(data, vocab_size=2**13):\n",
    "    return tfds.features.text.SubwordTextEncoder.build_from_corpus(data, target_vocab_size=vocab_size)\n",
    "\n",
    "tokenizer_en = tokenizer_data(data=data_en)\n",
    "tokenizer_pt = tokenizer_data(data=data_pt)\n",
    "\n",
    "print('En vocab size: ', tokenizer_en.vocab_size)\n",
    "print('Pt vocab size: ', tokenizer_pt.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example:  [8191, 2458, 972, 2108, 3, 1, 2571, 8192]\n",
      "Output example:  [8116, 834, 705, 7, 3561, 8117]\n"
     ]
    }
   ],
   "source": [
    "def token_start_end(data, tokenizer):\n",
    "    vocab_size = tokenizer.vocab_size + 2\n",
    "    # adding start and end token in each setense\n",
    "    return [[vocab_size - 2] + tokenizer.encode(sentense) + [vocab_size - 1] for sentense in data]\n",
    "\n",
    "inputs = token_start_end(data=data_en, tokenizer=tokenizer_en)\n",
    "outputs = token_start_end(data=data_pt, tokenizer=tokenizer_pt)\n",
    "\n",
    "print('Input example: ', inputs[0])\n",
    "print('Output example: ', outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing setenses longer than 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1685300it [07:43, 3639.51it/s] \n",
      "66118it [00:10, 6408.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len inputs: 208990 | len outputs 208990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_longer_sentense(data, max_length=15):\n",
    "    idx_to_remove = [idx for idx, sentense in enumerate(data) if len(sentense) > max_length]\n",
    "\n",
    "    for idx in tqdm(reversed(idx_to_remove)):\n",
    "        # remove the same setense from the data\n",
    "        del inputs[idx]\n",
    "        del outputs[idx]\n",
    "\n",
    "remove_longer_sentense(data=inputs)\n",
    "remove_longer_sentense(data=outputs)\n",
    "\n",
    "print('len inputs: {} | len outputs {}'.format(len(inputs), len(outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding sentenses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input padded sequences example:  [8191 2458  972 2108    3    1 2571 8192    0    0    0    0    0    0\n",
      "    0]\n",
      "Output padded sequences example:  [8116  834  705    7 3561 8117    0    0    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "def padding_sequences(data, max_length):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(sequences=data, value=0, padding='post', maxlen=max_length)\n",
    "\n",
    "inputs = padding_sequences(data=inputs, max_length=15)\n",
    "outputs = padding_sequences(data=outputs, max_length=15)\n",
    "\n",
    "print('Input padded sequences example: ', inputs[0])\n",
    "print('Output padded sequences example: ', outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final dataset cration with tf optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 11:45:04.959098: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-07 11:45:04.960227: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-07 11:45:04.989977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:04.991537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.8095GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-04-07 11:45:04.991557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 11:45:05.053488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 11:45:05.053595: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-07 11:45:05.087645: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 11:45:05.097819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 11:45:05.162177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 11:45:05.173145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 11:45:05.284748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 11:45:05.284973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:05.285235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:05.285365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-07 11:45:05.287906: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-07 11:45:05.289142: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-07 11:45:05.289263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:05.289375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.8095GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-04-07 11:45:05.289402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 11:45:05.289422: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-07 11:45:05.289431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-07 11:45:05.289440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-07 11:45:05.289448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-07 11:45:05.289458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-07 11:45:05.289467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-07 11:45:05.289476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-07 11:45:05.289528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:05.289674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:05.289763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-07 11:45:05.290621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-07 11:45:06.588728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-07 11:45:06.588755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-07 11:45:06.588761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-07 11:45:06.589792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:06.589966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:06.590102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-07 11:45:06.590210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5132 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(tensors=(inputs, outputs))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(buffer_size=buffer_size).batch(batch_size=batch_size)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ PE(pos, 2i) = sin(pos * angles)$\n",
    "\n",
    "$ PE(pos, 2i + 1) = cos(pos * angles)$\n",
    "\n",
    "\n",
    "$ angles = \\frac{1}{10000^{2*i / dmodel}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "    def get_angles(self, i, d_model):\n",
    "        # definition of angles\n",
    "        return 1 / np.power(10000., (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "\n",
    "        # get the pos and i matrix to gerate positional encoding from a input tensor\n",
    "        pos = np.arange(seq_length)[:, np.newaxis]\n",
    "        i = np.arange(d_model)[np.newaxis, :]\n",
    "\n",
    "        # calculates the angle results\n",
    "        angles = self.get_angles(i=i, d_model=d_model)\n",
    "\n",
    "        # calculates the positional encoding\n",
    "        pe = pos * angles #(seq_length, d_model)\n",
    "        pe[:, 0::2] = np.sin(pe[:, 0::2]) #even position\n",
    "        pe[:, 1::2] = np.cos(pe[:, 1::2]) #odd position\n",
    "\n",
    "        # transform the pos encoding dimension to the same as the input\n",
    "        pos_encoding = pe[np.newaxis, ...]\n",
    "\n",
    "        print('Inputs shape: {} | PE shape {} | Pos encoding shape: {}'.format(inputs.shape, pe.shape, pos_encoding.shape))\n",
    "        \n",
    "        print('Pos encoding', pos_encoding)\n",
    "\n",
    "        return inputs + pos_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing positional encoding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: (1, 4, 4) | PE shape (4, 4) | Pos encoding shape: (1, 4, 4)\n",
      "Pos encoding [[[ 0.          1.          0.          1.        ]\n",
      "  [ 0.84147098  0.54030231  0.00999983  0.99995   ]\n",
      "  [ 0.90929743 -0.41614684  0.01999867  0.99980001]\n",
      "  [ 0.14112001 -0.9899925   0.0299955   0.99955003]]]\n",
      "Inputs + pos encoding tf.Tensor(\n",
      "[[[1.        2.        1.        2.       ]\n",
      "  [1.841471  1.5403023 1.0099999 1.9999499]\n",
      "  [1.9092975 0.5838531 1.0199987 1.9998   ]\n",
      "  [1.14112   0.0100075 1.0299954 1.9995501]]], shape=(1, 4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pos = PositionalEncoding()\n",
    "\n",
    "matrix_test = tf.ones((1, 4, 4))\n",
    "\n",
    "print('Inputs + pos encoding', pos(matrix_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention mecanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled dot product Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![scaled dot product attention](imgs/scaled-dot-produt-attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Attention(Q, K, V) = softmax(\\frac{QK^{T}}{\\sqrt{d_{k}}})*V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q = queries\n",
    "\n",
    "K = keys\n",
    "\n",
    "V = values\n",
    "\n",
    "$K^{T}$ = K matrix transpose\n",
    "\n",
    "$d_{k}$ = K dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "\n",
    "    scaled_produt = product / tf.math.sqrt(keys_dim)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_produt += (mask * -1e9)\n",
    "\n",
    "    softmax = tf.nn.softmax(scaled_produt, axis=-1)\n",
    "\n",
    "    return tf.matmul(softmax, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mult-head attention](imgs/multi-head-attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, num_proj):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "\n",
    "        self.num_proj = num_proj\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d_model = input_shape[-1]\n",
    "        assert d_model % self.num_proj == 0\n",
    "\n",
    "        self.d_proj = d_model // self.num_proj\n",
    "\n",
    "        # linear dense layers\n",
    "        self.query_linear_dense = layers.Dense(units = self.d_model)\n",
    "        self.keys_linear_dense = layers.Dense(units = self.d_model)\n",
    "        self.values_linear_dense = layers.Dense(units = self.d_model)\n",
    "\n",
    "        self.final_linear_dense = layers.Dense(units = self.d_model)\n",
    "\n",
    "    def split_proj(self, inputs, batch_size):\n",
    "        shape = (batch_size, -1, self.d_proj)\n",
    "        splitted_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, num_proj, d_proj)\n",
    "\n",
    "        return tf.transpose(splitted_inputs, perm=[0, 2, 1, 3]) # (batch_size, num_proj, seq_length, d_proj)\n",
    "\n",
    "    def scaled_dot_product_attention(self, queries, keys, values, mask=None):\n",
    "        product = tf.matmul(queries, keys, transpose_b=True)\n",
    "        keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "\n",
    "        scaled_produt = product / tf.math.sqrt(keys_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_produt += (mask * -1e9)\n",
    "\n",
    "        softmax = tf.nn.softmax(scaled_produt, axis=-1)\n",
    "\n",
    "        return tf.matmul(softmax, values)\n",
    "\n",
    "    def call(self, queries, keys, values, mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "\n",
    "        queries = self.query_linear_dense(queries)\n",
    "        keys = self.keys_linear_dense(keys)\n",
    "        values = self.values_linear_dense(values)\n",
    "\n",
    "        queries = self.split_proj(inputs=queries, batch_size=batch_size)\n",
    "        keys = self.split_proj(inputs=keys, batch_size=batch_size)\n",
    "        values = self.split_proj(inputs=values, batch_size=batch_size)\n",
    "\n",
    "        attention = self.scaled_dot_product_attention(queries = queries,\n",
    "                                                      keys = keys,\n",
    "                                                      values = values,\n",
    "                                                      mask=mask)\n",
    "\n",
    "        # return the same shape as the input\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat = tf.concat(attention, shape=(batch_size, -1, self.d_model))\n",
    "\n",
    "        return self.final_linear_dense(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, ff_units, num_proj, dropout_rate):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.ff_units = ff_units\n",
    "        self.num_proj = num_proj\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(num_proj=self.num_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6) #1e-6 = 0.0000001\n",
    "\n",
    "        self.dense_1 = layers.Dense(units=self.ff_units)\n",
    "        self.dense_2 = layers.Dense(units=self.ff_units)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout_rate)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs, mask, training:bool):\n",
    "        attention = self.multi_head_attention(queries = inputs,\n",
    "                                              keys = inputs,\n",
    "                                              values = inputs,\n",
    "                                              mask = mask)\n",
    "        attention = self.dropout_1(attention, training = training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "\n",
    "        outputs = self.dense_1(attention)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs, training = training)\n",
    "\n",
    "        outputs = self.norm_2(outputs + attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cbe59bc8e43c33e263d0ddce44ad7ec5ba3f57d4d2daa17d616eb06d4130f325"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
